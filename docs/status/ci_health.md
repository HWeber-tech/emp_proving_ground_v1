# CI Health Snapshot

This dashboard summarizes the current state of the "CI" workflow and points to
where to find richer telemetry. Update the metrics after significant
infrastructure changes or once per sprint so stakeholders can confirm the
pipeline remains healthy at a glance.

## Latest pipeline status

| Signal | Value | Notes |
| --- | --- | --- |
| Last successful run | Refer to the GitHub Actions **CI** workflow page | Capture the run URL in team status updates. |
| Coverage (pytest `--cov`) | 76% (from [CI Baseline – 2025-09-16](../ci_baseline_report.md)) | Update when the coverage target moves. |
| Coverage & formatter trendlines | `tools/telemetry/update_ci_metrics.py` now records coverage percentages, per-domain coverage snapshots, optional remediation snapshots, and formatter mode metadata to `tests/.telemetry/ci_metrics.json`, giving dashboards historical trendlines plus lagging-domain alerts without bespoke scripts. Tests document the JSON contract for all four feeds. Use `python -m tools.telemetry.coverage_matrix --coverage-report coverage.xml` to emit standalone breakdowns when refreshing context packs. 【F:tools/telemetry/update_ci_metrics.py†L1-L240】【F:tools/telemetry/ci_metrics.py†L1-L260】【F:tests/tools/test_ci_metrics.py†L1-L420】【F:tests/.telemetry/ci_metrics.json†L1-L6】【F:tools/telemetry/coverage_matrix.py†L1-L196】【F:tests/tools/test_coverage_matrix.py†L1-L123】 |
| Remediation progress telemetry | `tools/telemetry/update_ci_metrics.py` accepts `--remediation-status` entries and the new `--coverage-remediation` mode to append roadmap progress snapshots (label, evidence source, key/value remediation statuses) and coverage laggard summaries (counts, thresholds, worst domain) to `tests/.telemetry/ci_metrics.json`, giving dashboards a structured feed for tracking quality/observability remediation across sprints. pytest covers the CLI parsing contract, coverage-note defaults, and JSON serialisation. 【F:tools/telemetry/update_ci_metrics.py†L1-L240】【F:tools/telemetry/ci_metrics.py†L1-L260】【F:tests/tools/test_ci_metrics.py†L1-L420】【F:tests/.telemetry/ci_metrics.json†L1-L6】 |
| Remediation summary export | `python -m tools.telemetry.remediation_summary` reads the metrics JSON and renders Markdown tables with delta call-outs, honours `--limit` for trimmed reports, omits deltas for non-numeric statuses, and supports writing directly to files under pytest coverage so release managers can drop the newest snapshot into updates without manual collation. 【F:tools/telemetry/remediation_summary.py†L1-L220】【F:tests/tools/test_remediation_summary.py†L22-L125】 |
| Formatter rollout | Repo-wide Ruff enforcement is live; the allowlist and helper script were removed after formatting all Stage 4 directories. | Guarded by `ruff format --check .` in CI; keep telemetry up to date via `python -m tools.telemetry.update_ci_metrics --formatter-mode global`. |
| Risk guardrail coverage | Drawdown throttling, Kelly sizing, min/max sizing bounds, mandatory stop-loss enforcement, minimum position sizing, equity budget validation, and aggregate exposure/leverage limits are exercised via `tests/current/test_risk_manager_impl.py`, `tests/trading/test_risk_policy.py`, and the expanded gateway regression suite. Config-level validation now enforces positive sizing, cross-field exposure relationships, and research-mode overrides while the runtime builder and deterministic risk API raise typed errors and emit canonical metadata snapshots, keeping compliance reviewers ahead of violations. Policy decisions now emit `telemetry.risk.policy` snapshots with Markdown summaries surfaced in the control centre and runtime status feeds. | Extend to FIX execution/risk integration paths next. 【F:src/risk/risk_manager_impl.py†L1-L360】【F:src/risk/real_risk_manager.py†L1-L170】【F:tests/current/test_risk_manager_impl.py†L1-L200】【F:src/trading/risk/risk_policy.py†L120-L246】【F:tests/trading/test_risk_policy.py†L69-L240】【F:src/trading/risk/policy_telemetry.py†L1-L195】【F:tests/trading/test_risk_policy_telemetry.py†L1-L109】【F:src/operations/bootstrap_control_center.py†L1-L260】【F:src/runtime/predator_app.py†L1-L360】【F:src/config/risk/risk_config.py†L1-L161】【F:tests/risk/test_risk_config_validation.py†L1-L36】【F:src/trading/risk/risk_api.py†L1-L134】【F:src/runtime/runtime_builder.py†L313-L343】【F:tests/trading/test_risk_api.py†L1-L115】【F:tests/runtime/test_runtime_builder.py†L158-L200】|
| Execution engine coverage | Partial fills, retries, and reconciliation flows locked in by `tests/current/test_execution_engine.py` and exercised end-to-end via `tests/current/test_orchestration_execution_risk_integration.py`. | Track reconciliation snapshots in future regression runs. |
| Orchestration ⇄ risk ⇄ execution | `tests/current/test_orchestration_execution_risk_integration.py` runs the orchestrator stubs through risk sizing and the execution engine, and the new fallback scenario drives the bootstrap trading stack against the async event bus to ensure telemetry still records when the bus is offline.【F:tests/current/test_orchestration_execution_risk_integration.py†L31-L284】 | Extend to include sensory fixtures once the WHY regression slice lands. |
| Runtime & event bus OpenTelemetry spans | `configure_event_bus_tracer` wires OpenTelemetry tracers into `AsyncEventBus`, tagging publish and handler spans with queue depth and dispatch lag, and the runtime builder reuses the same provider so startup/shutdown hooks, workload execution, and Timescale ingest orchestration emit spans with plan and fallback metadata.【F:src/observability/tracing.py†L1-L244】【F:src/runtime/runtime_builder.py†L250-L408】【F:src/runtime/runtime_builder.py†L1996-L2320】【F:tests/core/test_event_bus_tracing.py†L1-L118】【F:tests/runtime/test_runtime_tracing.py†L1-L134】 | Enable via `OTEL_ENABLED=true` plus `OTEL_EXPORTER_OTLP_*` extras when an OTLP collector is available; disable to fall back to the no-op tracer. |
| Event bus health guardrails | `evaluate_event_bus_health` escalates queue backlogs, dropped events, handler errors, and idle periods while `publish_event_bus_health` now rides the shared failover helper to log runtime failures, fall back to the global bus, and raise typed errors when both transports degrade. Guardrail regressions document backlog thresholds, metadata propagation, and failover escalation so CI catches degraded telemetry fan-out paths.【F:src/operations/event_bus_health.py†L143-L259】【F:tests/operations/test_event_bus_health.py†L22-L235】 | Subscribe to `telemetry.event_bus.health` on the runtime bus; monitor warnings for backlogs or fallbacks and investigate immediately when errors surface. |
| Execution readiness telemetry failover | `publish_execution_snapshot` now reuses the shared failover helper, logging runtime publish failures, falling back when `publish_from_sync` returns `None`, and escalating unexpected runtime/global bus errors so execution readiness snapshots keep flowing even when the primary transport degrades. | Subscribe to `telemetry.operational.execution` on the runtime bus or rely on the global bus fallback; pytest locks the fallback contract and payload structure.【F:src/operations/execution.py†L611-L648】【F:tests/operations/test_execution.py†L100-L134】 |
| Structured runtime logging | `configure_structured_logging` emits JSON log lines with runtime, tier, and connection metadata whenever `RUNTIME_LOG_STRUCTURED` extras are enabled. Formatter and builder tests cover the handler contract so on-call drills can rely on consistent log output.【F:src/observability/logging.py†L1-L122】【F:src/runtime/runtime_builder.py†L1838-L1877】【F:tests/observability/test_logging.py†L1-L74】【F:tests/runtime/test_runtime_builder.py†L600-L676】 | Toggle via `RUNTIME_LOG_STRUCTURED=true` and adjust verbosity with `RUNTIME_LOG_LEVEL`; supply `RUNTIME_LOG_CONTEXT` JSON to append deployment identifiers. |
| Data foundation config coverage | YAML loader fallbacks and overrides regression-tested via `tests/current/test_data_foundation_config_loading.py` | Keep expanding toward operational metrics and sensory signal hotspots. |
| Timescale ingest telemetry | `evaluate_ingest_health` publishes `telemetry.ingest.health` events after each orchestrated run and the runtime mirrors the reports to Kafka, giving dashboards and streaming consumers the same freshness/completeness snapshot. Regression suites now drive the backbone orchestrator through empty plans, lifecycle hooks, publisher metadata, and intraday safeguards so telemetry keeps reflecting institutional ingest posture. | Subscribe via the runtime event bus, consume the Kafka topic configured through `KAFKA_INGEST_HEALTH_TOPIC`, or rely on the Kafka ingest consumer bridge that now replays ingest topics into the runtime bus during institutional runs.【F:src/runtime/runtime_builder.py†L445-L653】【F:src/data_foundation/streaming/kafka_stream.py†L600-L924】【F:tests/data_foundation/test_kafka_stream.py†L120-L332】【F:tests/data_foundation/test_timescale_backbone_orchestrator.py†L1-L150】【F:tests/data_foundation/test_timescale_ingest.py†L322-L359】 |
| Timescale ingest metrics | `summarise_ingest_metrics` aggregates ingest results into per-dimension metrics and the runtime emits them on `telemetry.ingest.metrics`, giving CI a lightweight feed for dashboards while tests cover the snapshot contract. | Use the runtime event bus or the Kafka metrics topic (`KafkaIngestMetricsPublisher`) to subscribe to `telemetry.ingest.metrics`; snapshot payloads include total rows, freshness, and symbol coverage for each dimension.【F:src/runtime/runtime_builder.py†L577-L593】【F:src/data_foundation/ingest/metrics.py†L1-L88】【F:src/data_foundation/streaming/kafka_stream.py†L1022-L1135】【F:tests/data_foundation/test_ingest_metrics.py†L1-L45】 |
| Timescale ingest quality | `evaluate_ingest_quality` grades coverage/freshness into a score published on `telemetry.ingest.quality` while `KafkaIngestQualityPublisher` mirrors the report for downstream consumers, giving CI visibility into density gaps before failover triggers. | Subscribe to `telemetry.ingest.quality` on the runtime bus or configure `KAFKA_INGEST_QUALITY_TOPIC` to stream reports; pytest covers quality scoring and the Kafka publisher contract.【F:src/runtime/runtime_builder.py†L649-L706】【F:src/data_foundation/ingest/quality.py†L1-L208】【F:src/data_foundation/streaming/kafka_stream.py†L1126-L1287】【F:tests/data_foundation/test_ingest_quality.py†L1-L60】【F:tests/data_foundation/test_kafka_stream.py†L200-L310】 |
| Timescale ingest trends | `evaluate_ingest_trends` analyses recent ingest journal entries into `telemetry.ingest.trends` snapshots so operators and dashboards can spot row-count drops or freshness regressions across runs while the runtime summary stores the latest snapshot. New guardrails log runtime publish failures, raise on unexpected exceptions, and escalate global-bus outages under pytest coverage. | Subscribe to `telemetry.ingest.trends` on the runtime bus or inspect the `ingest_trends` block in `ProfessionalPredatorApp.summary()`; pytest covers the evaluator, publisher fallback paths, and summary exposure.【F:src/operations/ingest_trends.py†L1-L336】【F:src/runtime/runtime_builder.py†L900-L1090】【F:src/runtime/predator_app.py†L680-L735】【F:tests/operations/test_ingest_trends.py†L1-L148】【F:tests/runtime/test_professional_app_timescale.py†L240-L330】 |
| Cache health telemetry | `evaluate_cache_health` snapshots Redis configuration, hit/miss ratios, and eviction metadata while `publish_cache_health` now logs primary bus failures, records unexpected exceptions, and raises when the global bus is offline. | Subscribe to `telemetry.cache.health` on the runtime bus; pytest covers evaluator metadata, runtime fallback logging, and error escalation guardrails.【F:src/operations/cache_health.py†L1-L303】【F:tests/operations/test_cache_health.py†L1-L131】 |
| Timescale data retention | `evaluate_data_retention` grades Timescale daily, intraday, and macro tables against institutional retention policies, emits `telemetry.data_backbone.retention`, and records the markdown snapshot in the professional runtime so operators can confirm historical coverage before compliance reviews. | Subscribe to `telemetry.data_backbone.retention`, inspect the `data_retention` block in `ProfessionalPredatorApp.summary()`, or replay the pytest coverage capturing evaluation, runtime wiring, and summary exposure.【F:src/operations/retention.py†L1-L192】【F:src/runtime/runtime_builder.py†L1080-L1210】【F:src/runtime/predator_app.py†L150-L360】【F:tests/operations/test_data_retention.py†L1-L118】【F:tests/runtime/test_runtime_builder.py†L200-L360】【F:tests/runtime/test_professional_app_timescale.py†L600-L720】 |
| Data backbone readiness | `evaluate_data_backbone_readiness` fuses ingest health, quality, recovery, backup posture, Redis/Kafka wiring, scheduler status, and Spark export outcomes into `telemetry.data_backbone.readiness` so dashboards and runtime summaries expose a single institutional readiness snapshot. Latest regressions assert optional-trigger degradation, failover decisions, and recovery-plan metadata to keep drill-down evidence intact. | Subscribe to the runtime bus topic `telemetry.data_backbone.readiness` or read the `data_backbone` section of `ProfessionalPredatorApp.summary()`; pytest covers the snapshot contract, recovery metadata, and runtime integration. Operational responders can rely on the paired [Redis cache outage](../operations/runbooks/redis_cache_outage.md) and [Kafka ingest offset recovery](../operations/runbooks/kafka_ingest_offset_recovery.md) runbooks when those components degrade.【F:src/operations/data_backbone.py†L488-L515】【F:tests/operations/test_data_backbone.py†L289-L347】【F:src/runtime/runtime_builder.py†L657-L1180】【F:src/runtime/predator_app.py†L200-L520】【F:docs/operations/runbooks/redis_cache_outage.md†L1-L60】【F:docs/operations/runbooks/kafka_ingest_offset_recovery.md†L1-L66】 |
| Kafka readiness telemetry | `evaluate_kafka_readiness` blends connection settings, topic provisioning, publisher counts, and consumer lag snapshots into `telemetry.kafka.readiness`, and the runtime publishes plus records the markdown summary so professional operators can audit streaming posture alongside ingest feeds. | Subscribe to `telemetry.kafka.readiness` on the runtime bus, inspect the `kafka_readiness` block in `ProfessionalPredatorApp.summary()`, or replay the evaluator/runtime pytest coverage to confirm thresholds and metadata wiring.【F:src/operations/kafka_readiness.py†L1-L213】【F:src/runtime/runtime_builder.py†L600-L930】【F:src/runtime/predator_app.py†L200-L400】【F:tests/operations/test_kafka_readiness.py†L1-L97】【F:tests/runtime/test_runtime_builder.py†L665-L782】【F:tests/runtime/test_professional_app_timescale.py†L1116-L1160】 |
| Data backbone validation | `evaluate_data_backbone_validation` verifies Timescale settings, Redis/Kafka expectations, and scheduler telemetry, publishing `telemetry.data_backbone.validation` while the professional runtime logs the markdown snapshot so operators can confirm institutional toggles before ingest runs. | Subscribe to `telemetry.data_backbone.validation` or inspect the `data_backbone_validation` block in `ProfessionalPredatorApp.summary()`; pytest covers the validation contract plus runtime publication and recording. Timescale ingest now halts on validation failure, emits degraded readiness snapshots, and falls back to DuckDB so misconfigured institutional runs fail safe.【F:src/operations/data_backbone.py†L120-L320】【F:src/runtime/runtime_builder.py†L650-L780】【F:src/runtime/predator_app.py†L150-L370】【F:tests/operations/test_data_backbone.py†L120-L220】【F:tests/runtime/test_runtime_builder.py†L180-L280】【F:tests/runtime/test_professional_app_timescale.py†L395-L460】【F:tests/data_foundation/test_ingest_journal.py†L300-L374】 |
| Data backbone snapshot export | `tools/telemetry/export_data_backbone_snapshots.py` builds the professional runtime, extracts readiness/validation/retention/ingest trend + scheduler/Kafka blocks, and emits a single JSON payload for Grafana/DataDog dashboards. | Run `python -m tools.telemetry.export_data_backbone_snapshots --output backbone.json` during drills to capture the backbone posture without parsing Markdown; pytest covers exporter success cases and the missing-section guardrail.【F:tools/telemetry/export_data_backbone_snapshots.py†L1-L147】【F:tests/tools/test_data_backbone_export.py†L1-L74】 |
| Professional readiness telemetry | `evaluate_professional_readiness` now incorporates the aggregated operational readiness snapshot (system validation, incident response, ingest SLO posture) alongside data backbone, backup, and recovery metadata, publishing the combined payload on the runtime bus and recording Markdown summaries in `ProfessionalPredatorApp.summary()`. Latest enrichment adds `status_breakdown` and `component_statuses` metadata so dashboards can render severity chips directly from the payload. | Subscribe to `telemetry.operational.readiness` or inspect the `professional_readiness`/`operational_readiness` blocks in the runtime summary; pytest covers the aggregation helper plus runtime exposure of the merged readiness view, and the status page documents the contract.【F:src/operations/professional_readiness.py†L1-L210】【F:src/operations/operational_readiness.py†L1-L256】【F:src/runtime/runtime_builder.py†L360-L910】【F:src/runtime/predator_app.py†L200-L420】【F:tests/operations/test_operational_readiness.py†L1-L86】【F:docs/status/operational_readiness.md†L1-L34】【F:tests/runtime/test_professional_app_timescale.py†L722-L799】 |
| Governance report export | `python -m tools.telemetry.export_governance_report` loads compliance/regulatory snapshots, optionally collects audit evidence, emits JSON + Markdown, and persists history with metadata for cadence reviews. | Use the CLI to produce governance artefacts during drills; pytest covers snapshot loading, metadata parsing, Markdown emission, and persistence limits.【F:tools/telemetry/export_governance_report.py†L1-L260】【F:tests/tools/test_export_governance_report.py†L1-L139】 |
| Trade compliance telemetry | `TradeComplianceMonitor` evaluates execution reports against institutional policy thresholds, emits `telemetry.compliance.trade` snapshots, and records audit entries so runtime summaries and CI dashboards surface regulatory guardrails alongside ingest health. `TimescaleComplianceJournal` persists every snapshot in the `telemetry.compliance.audit` table so operators inherit a durable compliance trail and the runtime summary exposes the latest journal entry. | Subscribe to the runtime bus topic `telemetry.compliance.trade`, inspect the compliance section inside `ProfessionalPredatorApp.summary()`, or replay pytest coverage for policy enforcement, Timescale journaling, and runtime integration.【F:src/compliance/trade_compliance.py†L1-L420】【F:src/data_foundation/persist/timescale.py†L1-L900】【F:src/runtime/predator_app.py†L560-L720】【F:tests/compliance/test_trade_compliance.py†L1-L160】【F:tests/data_foundation/test_timescale_compliance_journal.py†L1-L44】【F:tests/runtime/test_professional_app_timescale.py†L232-L308】 |
| Compliance readiness telemetry | `evaluate_compliance_readiness` merges trade-compliance and KYC telemetry into a single readiness snapshot, publishes `telemetry.compliance.readiness` after each institutional ingest run, and records the markdown summary inside the runtime status report so operators inherit one regulatory posture surface. | Subscribe to `telemetry.compliance.readiness`, inspect the `compliance_readiness` block in `ProfessionalPredatorApp.summary()`, or replay the readiness pytest coverage and runtime builder test to confirm the aggregate feed stays stable.【F:src/operations/compliance_readiness.py†L1-L237】【F:src/runtime/runtime_builder.py†L1200-L1288】【F:src/runtime/predator_app.py†L52-L216】【F:tests/operations/test_compliance_readiness.py†L1-L76】【F:tests/runtime/test_runtime_builder.py†L150-L228】 |
| Compliance workflow telemetry | `evaluate_compliance_workflows` packages MiFID II, Dodd-Frank, and KYC checklists into `telemetry.compliance.workflow`, publishes Markdown-backed snapshots, and records the latest workflow block in the professional runtime summary. | Subscribe to `telemetry.compliance.workflow`, inspect the `compliance_workflows` block in `ProfessionalPredatorApp.summary()`, or replay the pytest coverage that exercises the workflow builder, publisher, and runtime integration.【F:src/compliance/workflow.py†L1-L760】【F:src/runtime/runtime_builder.py†L1200-L1336】【F:src/runtime/predator_app.py†L1-L520】【F:tests/compliance/test_compliance_workflow.py†L1-L140】【F:tests/runtime/test_runtime_builder.py†L160-L240】【F:tests/runtime/test_professional_app_timescale.py†L200-L320】 |
| Governance reporting cadence | `should_generate_report` gates the reporting interval, `collect_audit_evidence` and `generate_governance_report` fuse compliance readiness, regulatory telemetry, and Timescale audit evidence, and `publish_governance_report` emits `telemetry.compliance.governance` snapshots while `persist_governance_report` maintains a JSON history for reviews. | Subscribe to `telemetry.compliance.governance`, persist cadence outputs for audit drills, or replay the pytest coverage that documents section escalation, cadence timing, publishing fallbacks, and history trimming.【F:src/operations/governance_reporting.py†L1-L520】【F:tests/operations/test_governance_reporting.py†L1-L152】 |
| Strategy performance telemetry | `evaluate_strategy_performance` aggregates trading-manager experiment events and ROI snapshots into `telemetry.strategy.performance`, publishes Markdown summaries, and the professional runtime records the latest block so desks can monitor execution/rejection mix per strategy alongside ROI posture. | Subscribe to `telemetry.strategy.performance`, inspect the `strategy_performance` block in `ProfessionalPredatorApp.summary()`, or replay the pytest coverage that exercises the evaluator, runtime builder integration, and summary exposure.【F:src/operations/strategy_performance.py†L1-L537】【F:src/runtime/runtime_builder.py†L2236-L2294】【F:src/runtime/predator_app.py†L200-L986】【F:tests/runtime/test_runtime_builder.py†L272-L523】【F:tests/runtime/test_professional_app_timescale.py†L200-L270】 |
| Strategy governance telemetry | Strategy registry persistence now records catalogue provenance for every champion while the compliance workflow checklist exposes a "Strategy governance" block that consumes the registry summary so approvals mirror the seeded desk templates. | Inspect the `strategy_registry` section in `ProfessionalPredatorApp.summary()` or review the workflow snapshot; pytest covers registry provenance and the governance checklist.【F:src/governance/strategy_registry.py†L1-L420】【F:src/compliance/workflow.py†L1-L760】【F:src/runtime/predator_app.py†L1-L520】【F:tests/governance/test_strategy_registry.py†L1-L60】【F:tests/compliance/test_compliance_workflow.py†L1-L140】 |
| KYC/AML telemetry | `KycAmlMonitor` grades onboarding dossiers, emits `telemetry.compliance.kyc` snapshots with markdown context, and can journal cases into `telemetry.compliance_kyc` so institutional teams audit reviewer activity alongside trade compliance telemetry. The professional runtime wires the monitor behind extras, exposes the latest case snapshot in `summary()`, and pytest covers the monitor contract plus Timescale round-trips. | Enable via `KYC_MONITOR_ENABLED` extras, subscribe to `telemetry.compliance.kyc`, or review the `kyc` block in `ProfessionalPredatorApp.summary()`; pytest exercises the monitor, journal, and runtime integration.【F:src/compliance/kyc.py†L1-L332】【F:src/data_foundation/persist/timescale.py†L920-L1265】【F:src/runtime/predator_app.py†L80-L390】【F:tests/compliance/test_kyc_monitor.py†L1-L70】【F:tests/data_foundation/test_timescale_compliance_journal.py†L1-L78】【F:tests/runtime/test_professional_app_timescale.py†L200-L308】 |
| Risk/compliance evidence export | `tools.telemetry/export_risk_compliance_snapshots.py` captures risk policy, execution readiness, compliance readiness/workflows, and Timescale journal stats in a governance-ready JSON bundle so reviewers can export evidence without bespoke SQL. | Run `python -m tools.telemetry.export_risk_compliance_snapshots --output governance.json` to collect the payload; pytest covers the CLI contract while journal tests exercise the aggregation helpers.【F:tools/telemetry/export_risk_compliance_snapshots.py†L1-L308】【F:tests/tools/test_risk_compliance_export.py†L1-L113】【F:src/data_foundation/persist/timescale.py†L1211-L2163】【F:tests/data_foundation/test_timescale_compliance_journal.py†L57-L206】【F:tests/data_foundation/test_timescale_execution_journal.py†L86-L123】 |
| Runtime task supervision | `TaskSupervisor` funnels Kafka bridges, ingest schedulers, and other runtime background work through a managed cancellation/logging layer, and the runtime summary now exposes active task metadata for operators. | Audit active tasks via `ProfessionalPredatorApp.active_background_tasks` or the `background_task_details` section of `summary()`; replay the pytest suite covering task supervision to confirm cancellations and metadata reporting remain stable.【F:src/runtime/task_supervisor.py†L1-L152】【F:src/runtime/predator_app.py†L95-L352】【F:tests/runtime/test_task_supervisor.py†L1-L64】【F:tests/runtime/test_professional_app_timescale.py†L1-L120】 |
| Runtime health endpoint | `RuntimeHealthServer` serves `/health` with FIX connectivity, market-data freshness, and telemetry exporter checks, and the runtime builder starts the server automatically when healthchecks are enabled. | Hit the configured endpoint (defaults to `0.0.0.0:8080/health`) to confirm status, override via `RUNTIME_HEALTHCHECK_*` extras, and rely on the pytest coverage for evaluator/server wiring.【F:src/runtime/healthcheck.py†L1-L258】【F:src/runtime/runtime_builder.py†L1816-L1863】【F:tests/runtime/test_healthcheck.py†L1-L170】 |
| Runtime CLI coverage | `emp-runtime` wraps the runtime builder with `summary`, `run`, `ingest-once`, and `restart` commands that honour signal-aware shutdowns and optional timeouts so operators can rehearse ingestion-only or restart drills from the command line. | Run `python -m src.runtime.cli --help`, use `--no-trading`/`--timeout` during rehearsals, and rely on the CLI pytest coverage for JSON summary output and restart sequencing.【F:src/runtime/cli.py†L1-L258】【F:tests/runtime/test_runtime_cli.py†L1-L88】 |
| Event bus health telemetry | `evaluate_event_bus_health` captures queue depth, dropped events, and handler errors into `telemetry.event_bus.health`, publishes the snapshot after ingest, and records the markdown summary in professional runtime reports. The publisher now delegates to the shared failover helper, logging runtime failures, skipping redundant fallbacks, and escalating to the global bus with typed errors so diagnostics stay visible. | Subscribe to `telemetry.event_bus.health`, inspect the `event_bus` block in `ProfessionalPredatorApp.summary()`, or replay the pytest suites covering the evaluator, runtime wiring, and summary exposure.【F:src/operations/event_bus_health.py†L143-L259】【F:src/runtime/runtime_builder.py†L1872-L1916】【F:src/runtime/predator_app.py†L200-L380】【F:tests/operations/test_event_bus_health.py†L22-L206】【F:tests/runtime/test_professional_app_timescale.py†L380-L452】 |
| System validation telemetry | `evaluate_system_validation` ingests the concept-aligned validation report, publishes `telemetry.operational.system_validation`, surfaces the Markdown summary via the professional runtime block, and now warns on runtime bus failures before falling back to the global bus and raising unexpected errors. | Subscribe to `telemetry.operational.system_validation`, inspect the `system_validation` block in `ProfessionalPredatorApp.summary()`, or replay the pytest suites covering the parser, fallback handling, runtime integration, and summary exposure.【F:src/operations/system_validation.py†L200-L312】【F:src/runtime/runtime_builder.py†L1905-L1950】【F:src/runtime/predator_app.py†L120-L360】【F:tests/operations/test_system_validation.py†L85-L137】【F:tests/runtime/test_professional_app_timescale.py†L400-L455】【F:tests/runtime/test_runtime_builder.py†L200-L360】 |
| Operational snapshot export | `tools/telemetry/export_operational_snapshots.py` packages the professional readiness, security, incident response, and system validation blocks into a JSON payload so Grafana/DataDog dashboards can ingest one file instead of scraping Markdown. | Run `python -m tools.telemetry.export_operational_snapshots --output telemetry.json` after institutional runs. pytest covers happy-path export, missing-section warnings, and the `--allow-missing` flag.【F:tools/telemetry/export_operational_snapshots.py†L1-L143】【F:tests/tools/test_operational_export.py†L1-L86】 |
| Risk posture telemetry | `evaluate_risk_posture` fuses portfolio monitor state and risk-gateway checks into `telemetry.risk.posture` events, `TradingManager` logs markdown summaries, and the runtime exposes the latest snapshot so CI dashboards inherit drawdown and open-position guardrail status alongside ingest and compliance feeds. | Subscribe to `telemetry.risk.posture`, inspect the `risk` section of `ProfessionalPredatorApp.summary()`, or replay the pytest coverage that exercises the telemetry helpers and runtime integration.【F:src/risk/telemetry.py†L1-L247】【F:src/trading/trading_manager.py†L1-L240】【F:src/runtime/predator_app.py†L200-L320】【F:tests/risk/test_risk_telemetry.py†L1-L102】【F:tests/current/test_bootstrap_control_center.py†L1-L180】【F:tests/current/test_bootstrap_runtime_integration.py†L1-L70】 |
| Configuration audit telemetry | `evaluate_configuration_audit` compares successive `SystemConfig` snapshots, grades tier/run-mode/credential changes, publishes `telemetry.runtime.configuration`, and records markdown-backed summaries on the professional runtime while Timescale persistence stores a durable audit trail. | Subscribe to `telemetry.runtime.configuration`, inspect the `configuration_audit` block in `ProfessionalPredatorApp.summary()`, or replay the pytest coverage and Timescale journal tests to confirm the snapshot contract and persistence; bootstrap-mode coverage now asserts the snapshot still emits without Timescale credentials before ingest builds.【F:src/operations/configuration_audit.py†L1-L308】【F:src/runtime/runtime_builder.py†L1-L260】【F:src/runtime/predator_app.py†L1-L400】【F:src/data_foundation/persist/timescale.py†L1-L2150】【F:tests/operations/test_configuration_audit.py†L1-L94】【F:tests/data_foundation/test_timescale_configuration_journal.py†L1-L47】【F:tests/runtime/test_professional_app_timescale.py†L1-L200】【F:tests/runtime/test_runtime_builder.py†L100-L220】 |
| ROI telemetry | `evaluate_roi_posture` converts portfolio equity, trade volume, and configured cost models into `telemetry.operational.roi` snapshots while the trading manager, control centre, and runtime summary publish markdown context for dashboards. | Subscribe to `telemetry.operational.roi`, inspect the `roi` sections of the control centre performance block or `ProfessionalPredatorApp.summary()`, or replay the ROI pytest contract covering cost modelling and publisher behaviour.【F:src/operations/roi.py†L1-L164】【F:src/trading/trading_manager.py†L1-L280】【F:src/operations/bootstrap_control_center.py†L1-L320】【F:src/runtime/predator_app.py†L400-L720】【F:tests/operations/test_roi.py†L1-L80】 |
| Kafka consumer lag telemetry | `capture_consumer_lag` parses Kafka client metrics and the ingest consumer can publish `telemetry.kafka.lag` snapshots with per-partition offsets, totals, and metadata so dashboards track lag alongside ingest payloads. | Enable via `KAFKA_INGEST_CONSUMER_PUBLISH_LAG` (or pass `publish_consumer_lag=True` programmatically); payloads include aggregated lag totals and respect configurable intervals, with pytest coverage documenting the feed and guardrails.【F:src/data_foundation/streaming/kafka_stream.py†L259-L415】【F:src/data_foundation/streaming/kafka_stream.py†L1700-L1919】【F:tests/data_foundation/test_kafka_stream.py†L453-L564】 |
| Timescale ingest observability | `build_ingest_observability_snapshot` composes metrics, health checks, recovery metadata, and failover decisions into a single payload that the runtime logs and publishes on `telemetry.ingest.observability`. | Capture the event via the runtime event bus for dashboards, export the markdown snapshot for runbooks, or replay the pytest contract for the observability snapshot to confirm the merged payload stays stable as ingest behaviour evolves.【F:src/data_foundation/ingest/observability.py†L1-L211】【F:src/runtime/runtime_builder.py†L624-L635】【F:tests/data_foundation/test_ingest_observability.py†L1-L110】 |
| Spark export telemetry | `execute_spark_export_plan` serialises Timescale query results into Spark-friendly datasets with manifests while the runtime publishes `telemetry.ingest.spark_exports` and records the snapshot in professional summaries. | Subscribe to `telemetry.ingest.spark_exports`, inspect the `spark_exports` block in `ProfessionalPredatorApp.summary()`, or run the spark export pytest suite to verify partitioning and runtime integration.【F:src/data_foundation/batch/spark_export.py†L1-L233】【F:src/runtime/runtime_builder.py†L657-L866】【F:src/runtime/predator_app.py†L1-L520】【F:tests/data_foundation/test_spark_export.py†L1-L129】【F:tests/data_foundation/test_ingest_journal.py†L360-L438】【F:tests/runtime/test_professional_app_timescale.py†L1-L620】 |
| Spark stress drill | `execute_spark_stress_drill` replays Spark export plans across configurable cycles, enforces duration thresholds, publishes `telemetry.ingest.spark_stress`, and the runtime summary exposes the latest drill snapshot for operators. | Subscribe to `telemetry.ingest.spark_stress`, review the `spark_stress` block in `ProfessionalPredatorApp.summary()`, or execute the spark stress pytest suite to confirm cycle recording and threshold handling.【F:src/operations/spark_stress.py†L1-L166】【F:src/runtime/runtime_builder.py†L774-L1256】【F:src/runtime/predator_app.py†L150-L860】【F:tests/operations/test_spark_stress.py†L1-L87】【F:tests/runtime/test_professional_app_timescale.py†L740-L813】 |
| Cache health telemetry | `evaluate_cache_health` evaluates Redis namespaces, hit/miss ratios, and eviction pressure and publishes the results on `telemetry.cache.health` while recording the markdown summary in the professional runtime. | Subscribe to `telemetry.cache.health`, review the `cache` block in `ProfessionalPredatorApp.summary()`, or replay the pytest coverage to confirm the snapshot contract and runtime integration.【F:src/operations/cache_health.py†L1-L191】【F:src/runtime/runtime_builder.py†L608-L741】【F:tests/runtime/test_professional_app_timescale.py†L300-L346】【F:tests/runtime/test_runtime_builder.py†L180-L268】 |
| Operational ingest SLO telemetry | `evaluate_ingest_slos` fuses ingest metrics, health status, and alert routes into an operational SLO snapshot and the runtime publishes `telemetry.operational.slos` alongside markdown summaries for ops drills. | Subscribe to `telemetry.operational.slos` on the event bus, configure overrides via `OPERATIONS_ALERT_ROUTES`, or replay the pytest contract under `tests/operations/test_slo.py` to confirm alert routing metadata and status escalation stay stable.【F:src/operations/slo.py†L1-L206】【F:src/runtime/runtime_builder.py†L624-L669】【F:src/data_foundation/ingest/configuration.py†L1-L244】【F:tests/operations/test_slo.py†L1-L70】 |
| Backup readiness telemetry | `evaluate_backup_readiness` merges Timescale backup policies with ingest health/quality outcomes to publish `telemetry.operational.backups`, log markdown snapshots, and store the latest status inside runtime summaries. | Subscribe to `telemetry.operational.backups`, inspect the `backups` block in `ProfessionalPredatorApp.summary()`, or replay the pytest coverage for backup evaluation and runtime integration.【F:src/operations/backup.py†L1-L206】【F:src/runtime/runtime_builder.py†L300-L360】【F:src/runtime/predator_app.py†L260-L380】【F:tests/operations/test_backup.py†L1-L80】【F:tests/runtime/test_professional_app_timescale.py†L160-L220】 |
| Execution readiness telemetry | `evaluate_execution_readiness` assesses fill and rejection rates, latency, drop-copy metrics, and connection health to publish `telemetry.operational.execution` while recording the markdown summary in professional runtime status reports. | Subscribe to `telemetry.operational.execution`, inspect the `execution` block in `ProfessionalPredatorApp.summary()`, or run the pytest suites covering the execution evaluator, trading manager instrumentation, and runtime integration.【F:src/operations/execution.py†L1-L430】【F:src/runtime/runtime_builder.py†L1700-L1840】【F:src/runtime/predator_app.py†L200-L360】【F:tests/operations/test_execution.py†L1-L110】【F:tests/trading/test_trading_manager_execution.py†L1-L80】【F:tests/runtime/test_professional_app_timescale.py†L360-L420】 |
| FIX pilot telemetry | `FixIntegrationPilot` supervises FIX sessions, `FixDropcopyReconciler` ingests drop-copy events, and `evaluate_fix_pilot` publishes `telemetry.execution.fix_pilot` so dashboards surface queue metrics, order posture, drop-copy reconciliation, and compliance coverage alongside execution readiness. | Subscribe to `telemetry.execution.fix_pilot`, review the `fix_pilot` block in `ProfessionalPredatorApp.summary()`, or replay the pilot/drop-copy pytest coverage documenting lifecycle supervision and reconciliation evaluation.【F:src/runtime/fix_pilot.py†L1-L210】【F:src/runtime/fix_dropcopy.py†L1-L228】【F:src/operations/fix_pilot.py†L1-L240】【F:src/runtime/runtime_builder.py†L2040-L2130】【F:tests/runtime/test_fix_pilot.py†L1-L190】【F:tests/runtime/test_fix_dropcopy.py†L1-L60】 |
| Execution readiness journal | `TimescaleExecutionJournal` records each execution readiness snapshot in Timescale and the professional runtime summary surfaces recent and latest entries so operators can audit historical execution posture. | Query the `telemetry.execution_snapshots` table or inspect the `execution_journal` block in `ProfessionalPredatorApp.summary()`; pytest exercises the journal round-trip and summary integration.【F:src/data_foundation/persist/timescale.py†L900-L1290】【F:tests/data_foundation/test_timescale_execution_journal.py†L1-L91】【F:tests/runtime/test_professional_app_timescale.py†L400-L460】 |
| Security posture telemetry | `evaluate_security_posture` grades MFA coverage, rotation cadences, incident drills, intrusion detection, and TLS posture into `telemetry.operational.security`, logging markdown snapshots, warning on runtime publish failures, and falling back to the global bus before raising unexpected errors. | Subscribe to `telemetry.operational.security`, inspect the `security` block in `ProfessionalPredatorApp.summary()`, or replay the security pytest coverage and runtime builder assertions (including fallback and escalation paths) to confirm telemetry publication.【F:src/operations/security.py†L420-L579】【F:src/runtime/runtime_builder.py†L1090-L1280】【F:src/runtime/predator_app.py†L120-L340】【F:tests/operations/test_security.py†L148-L263】【F:tests/runtime/test_runtime_builder.py†L120-L240】【F:tests/runtime/test_professional_app_timescale.py†L140-L260】 |
| Incident response telemetry | `evaluate_incident_response` blends runbook coverage, responder rosters, training cadence, and postmortem backlog metrics into `telemetry.operational.incident_response`, publishing markdown summaries and recording the latest snapshot in the professional runtime report. | Subscribe to `telemetry.operational.incident_response`, inspect the `incident_response` block in `ProfessionalPredatorApp.summary()`, or replay the incident-response pytest coverage that exercises the evaluator, publisher, runtime integration, and summary exposure.【F:src/operations/incident_response.py†L1-L233】【F:src/runtime/runtime_builder.py†L2160-L2215】【F:src/runtime/predator_app.py†L260-L360】【F:tests/operations/test_incident_response.py†L1-L108】【F:tests/runtime/test_runtime_builder.py†L360-L520】【F:tests/runtime/test_professional_app_timescale.py†L520-L600】 |
| Timescale ingest journal | `TimescaleIngestJournal` persists ingest run history (status, rows, freshness, plan metadata) in the shared Timescale cluster and `_record_ingest_journal` records every orchestrated run immediately after health evaluation. `plan_ingest_recovery` now appends recovery attempts (lookbacks, missing symbols, health status) so operators can see when the runtime auto-replayed degraded slices before considering failover. | Query the `telemetry_ingest_runs` table for audits, review the surfaced payload inside `ProfessionalPredatorApp.summary()` for a runtime-friendly view, or replay the pytest journal round-trip, recovery, and runtime integration tests to confirm the contract.【F:src/data_foundation/persist/timescale.py†L1-L720】【F:src/runtime/runtime_builder.py†L484-L570】【F:src/runtime/predator_app.py†L220-L317】【F:tests/data_foundation/test_ingest_recovery.py†L1-L95】【F:tests/data_foundation/test_ingest_journal.py†L120-L197】【F:tests/runtime/test_professional_app_timescale.py†L120-L196】 |
| Timescale ingest scheduler | `TimescaleIngestScheduler` runs the orchestrator plan on configurable intervals, now wiring through the runtime task supervisor with metadata so operators can inspect supervised ingest jobs instead of loose `create_task` handles. Guardrail coverage exercises steady-state loops, failure cut-offs, jitter bounds, supervisor telemetry, snapshot builders, and event publishing, and the guardrail manifest asserts the scheduler suite stays pinned to the guardrail marker. | Enable by setting `TIMESCALE_INGEST_SCHEDULE=true` (plus interval/jitter extras); monitor background task counts in `app.summary()` and rely on pytest coverage for jitter, failure, supervisor, snapshot, publishing, and guardrail-manifest enforcement.【F:src/data_foundation/ingest/scheduler.py†L1-L138】【F:src/data_foundation/ingest/configuration.py†L1-L210】【F:src/runtime/runtime_builder.py†L845-L869】【F:tests/data_foundation/test_ingest_scheduler.py†L1-L200】【F:tests/data_foundation/test_timescale_config.py†L120-L170】【F:tests/runtime/test_guardrail_suite_manifest.py†L18-L40】 |
| Timescale ingest failover guard | `decide_ingest_failover` evaluates health reports, emits `telemetry.ingest.failover` decisions, and automatically replays the DuckDB bootstrap ingest when required slices fail so operators can see the rollback in telemetry. | Monitor the runtime event bus for `telemetry.ingest.failover`, inspect the fallback reason in the payload, or replay the pytest coverage that documents the failover scenarios.【F:src/data_foundation/ingest/failover.py†L1-L120】【F:src/runtime/runtime_builder.py†L618-L650】【F:tests/data_foundation/test_ingest_failover.py†L1-L120】 |
| Timescale failover drill | `execute_failover_drill` mutates recent ingest results to simulate Timescale outages, verifies the failover policy, publishes `telemetry.ingest.failover_drill`, and records Markdown summaries in the professional runtime so operators can rehearse the DuckDB fallback during drills. | Subscribe to `telemetry.ingest.failover_drill`, review the `failover_drill` block inside `ProfessionalPredatorApp.summary()`, or run the failover drill pytest coverage to confirm fallback execution is still documented.【F:src/operations/failover_drill.py†L1-L213】【F:src/runtime/runtime_builder.py†L1015-L1072】【F:src/runtime/predator_app.py†L145-L180】【F:tests/operations/test_failover_drill.py†L1-L88】【F:tests/runtime/test_professional_app_timescale.py†L610-L650】 |
| Kafka ingest backfill & provisioning | `backfill_ingest_dimension_to_kafka` replays Timescale snapshots into configured ingest topics with `backfill` metadata so new environments inherit historical telemetry, and `KafkaTopicProvisioner` auto-creates ingest topics when `KAFKA_INGEST_AUTO_CREATE_TOPICS` is enabled so the runtime does not start with missing topics; pytest fixtures capture the payload and provisioning contracts.【F:src/data_foundation/streaming/kafka_stream.py†L226-L620】【F:tests/data_foundation/test_kafka_stream.py†L60-L420】 |
| Timescale cache coverage | `tests/data_foundation/test_timescale_cache.py` exercises `TimescaleQueryCache` cache hits, TTL expiry, and runtime connector integration so Redis-backed query paths stay observable as institutional runs land.【F:src/data_foundation/cache/timescale_query_cache.py†L1-L190】【F:tests/data_foundation/test_timescale_cache.py†L1-L160】 |
| Macro enrichment coverage | `tests/data_foundation/test_timescale_connectors.py::test_daily_connector_enriches_macro_bias` validates that Timescale connectors emit macro bias, confidence, and event metadata via `TimescaleMacroEventService`, keeping the WHY organ’s macro context observable.【F:src/data_foundation/services/macro_events.py†L1-L226】【F:src/data_foundation/fabric/timescale_connector.py†L1-L164】【F:tests/data_foundation/test_timescale_connectors.py†L1-L150】 |
| Sensory audit coverage | `tests/sensory/test_how_anomaly_sensors.py`, `tests/sensory/test_when_gamma.py`, `tests/sensory/test_why_yield.py`, the new `tests/sensory/test_real_sensory_organ.py`, and bootstrap runtime integration tests document dimensional outputs plus the fused audit trail and telemetry snapshot emitted by the integrated organ, keeping CI visibility on sensory diagnostics.【F:tests/sensory/test_how_anomaly_sensors.py†L1-L73】【F:tests/sensory/test_when_gamma.py†L1-L64】【F:tests/sensory/test_why_yield.py†L19-L85】【F:tests/sensory/test_real_sensory_organ.py†L1-L107】【F:tests/current/test_bootstrap_runtime_integration.py†L34-L64】 |
| Sensory drift telemetry | `evaluate_sensory_drift` publishes `telemetry.sensory.drift` snapshots while the runtime summary records the latest drift block so operators can monitor WHY/HOW deltas alongside ingest telemetry. Publisher now routes through the shared failover helper, logging runtime/global bus degradation and falling back deterministically under regression coverage.【F:src/operations/sensory_drift.py†L1-L276】【F:src/runtime/runtime_builder.py†L960-L1062】【F:src/runtime/predator_app.py†L320-L360】 | Subscribe to `telemetry.sensory.drift` via the runtime bus or inspect the `sensory_drift` block in `ProfessionalPredatorApp.summary()`; pytest exercises drift evaluation, runtime preference, and global-bus fallback handling.【F:tests/operations/test_sensory_drift.py†L17-L163】【F:tests/runtime/test_professional_app_timescale.py†L720-L780】 |
| Evolution catalogue telemetry | `EvolutionCycleOrchestrator` publishes `telemetry.evolution.catalogue` events whenever catalogue seeding is active, and pytest coverage captures both the population statistics and event payload so CI dashboards can surface the seeded desk metadata.【F:src/orchestration/evolution_cycle.py†L150-L360】【F:tests/current/test_population_manager_catalogue.py†L1-L39】【F:tests/current/test_evolution_orchestrator.py†L1-L170】【F:tests/evolution/test_catalogue_snapshot.py†L1-L43】 |
| Evolution lineage telemetry | `EvolutionLineageSnapshot` fuses champion fitness, parents, mutation history, and population stats into `telemetry.evolution.lineage` so dashboards can track how institutional genomes evolve away from their seeded catalogue entries.【F:src/evolution/lineage_telemetry.py†L1-L165】【F:src/orchestration/evolution_cycle.py†L120-L392】【F:tests/evolution/test_lineage_snapshot.py†L1-L74】【F:tests/current/test_evolution_orchestrator.py†L1-L190】 |
| Evolution experiment telemetry | `evaluate_evolution_experiments` aggregates paper-trading experiment events and ROI posture into `telemetry.evolution.experiments`, the trading manager records experiment events, and the runtime publishes and stores the snapshot for professional summaries.【F:src/operations/evolution_experiments.py†L1-L248】【F:src/trading/trading_manager.py†L1-L320】【F:src/runtime/runtime_builder.py†L2059-L2116】【F:src/runtime/predator_app.py†L848-L867】【F:tests/operations/test_evolution_experiments.py†L1-L114】【F:tests/runtime/test_professional_app_timescale.py†L840-L908】 |
| Evolution tuning telemetry | `evaluate_evolution_tuning` blends experiment telemetry with strategy performance snapshots into actionable `telemetry.evolution.tuning` recommendations, publishing the feed and storing the markdown in professional runtime summaries.【F:src/operations/evolution_tuning.py†L1-L443】【F:src/runtime/runtime_builder.py†L2566-L2649】【F:src/runtime/predator_app.py†L229-L515】【F:src/runtime/predator_app.py†L1098-L1104】【F:tests/operations/test_evolution_tuning.py†L1-L172】【F:tests/runtime/test_professional_app_timescale.py†L1298-L1338】 |
| Operational metrics coverage | `tests/operational/test_metrics.py` exercises logging escalation, exporter idempotence, lazy gauge fallbacks, FIX wrapper sanitisation, fallback invocation, and latency bounds so CI surfaces operational metric regressions deterministically. | Fold orchestration smoke tests into the suite to cover adapter wiring.【F:src/operational/metrics.py†L45-L200】【F:tests/operational/test_metrics.py†L200-L328】 |
| Pytest flake telemetry | `tests/.telemetry/flake_runs.json` emitted each run (repository copy currently mirrors CI runs #482–#483 for historical context); summarise via `python tools/telemetry/summarize_flakes.py`. | Override with `PYTEST_FLAKE_LOG` or `--flake-log-file`; upload alongside `pytest.log` and follow the observability plan for drill cadence. |
| Open CI alerts | Check the automatically managed **CI failure alerts** issue | Created/closed by `.github/workflows/ci-failure-alerts.yml`. |
| Slack relay | Enabled via `.github/workflows/ci-failure-alerts.yml` (`notify-slack`) when `SLACK_CI_WEBHOOK` is present | Mirrors run metadata into `#ci-alerts` so responders get chat and issue updates together; the job skips automatically if the secret is unset. |

## Where to look when something fails

1. **CI failure alerts issue / Slack relay** – Any failing `CI` run adds a
   comment to the `CI failure alerts` issue and, when configured, posts the same
   metadata to the `#ci-alerts` Slack channel. Resolve the failure, close the
   issue, and acknowledge the Slack message to clear the alert backlog.
2. **Pytest log artifact** – The `tests` job uploads `pytest.log` on every run
   (success or failure). Download it to inspect the full trace beyond the tail
   mirrored in the step summary.
3. **CI baseline report** – The baseline in [`docs/ci_baseline_report.md`](../ci_baseline_report.md)
   lists historical hotspots and still-relevant remediation tickets.

## Telemetry summary

| Metric | Value |
| --- | --- |
| Session start | 1758399822.4724245 |
| Session end | 1758399825.4168456 |
| Exit status | 0 (success) |
| Recorded events | 0 |
| Failing tests | _None recorded_ |
| Recent runs | Local execution capture (no CI backfill) |

## Maintenance checklist

- Confirm the alert issue auto-closes after the next successful run.
- Refresh coverage and formatter metrics after sizable refactors.
- Add notes about recurring flakes directly to this page so trends remain
  discoverable without mining historical logs.
- Verify the flake telemetry JSON uploads with each run (or override the
  location locally to avoid committing artifacts).
